{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'm1s3/Data/Yelp_Selected_Businesses.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7bb5c54c18b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# excel sheet names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mworkbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'm1s3/Data/Yelp_Selected_Businesses.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mworkbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mD:\\Software\\anaconda3\\envs\\learn-env\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'm1s3/Data/Yelp_Selected_Businesses.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./Data/ACS_16_5YR_B24011_with_ann.csv', usecols=['GEO.id', 'GEO.id2'], encoding='latin-1')\n",
    "# df = df.drop(0)\n",
    "df.head(2)\n",
    "\n",
    "# excel sheet names\n",
    "workbook = pd.ExcelFile('m1s3/Data/Yelp_Selected_Businesses.xlsx')\n",
    "workbook.sheet_names\n",
    "\n",
    "# save results\n",
    "# df.to_csv('NewSavedView.csv', index=False) #Notice how we have to pass index=False if we do not want it included in our output\n",
    "\n",
    "# supress scientific notation\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "# max rows / columns\n",
    "# pd.options.display.max_rows = 99999\n",
    "# pd.options.display.max_columns = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a function\n",
    "df = pd.read_csv('m1s3/Data/turnstile_180901.txt')\n",
    "def contains_n(text):\n",
    "    return 'N' in text\n",
    "\n",
    "df['On_N_Line'] = df.LINENAME.map(contains_n)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('m1s3/Data/turnstile_180901.txt')\n",
    "\n",
    "# change column data types\n",
    "df.ENTRIES = df.ENTRIES.astype(int)\n",
    "df.ENTRIES.dtype\n",
    "\n",
    "# dates\n",
    "# iloc slicing series / dataframes\n",
    "print(df.DATE.iloc[0])\n",
    "# pd.to_datetime(df.DATE, format='%m/%d/%Y').head()\n",
    "pd.to_datetime(df.DATE).head()\n",
    "# dt methods\n",
    "df.DATE = pd.to_datetime(df.DATE)\n",
    "df.DATE.dt.day_name().head()\n",
    "\n",
    "# rename / drop columns, set new index\n",
    "df = df.rename(columns = {'DATE': 'date'})\n",
    "df.columns = [col.title().strip() for col in df.columns]\n",
    "# df = df.drop('C/A', axis = 1) # If you don't pass the axis=1 parameter, pandas will try and drop a row with the specified index\n",
    "# df = df.set_index('UNIT')\n",
    "# df = df.reset_index()\n",
    "df.head()\n",
    "\n",
    "df.Date = pd.to_datetime(df.Date)\n",
    "df['Dayofweek'] = df.Date.dt.dayofweek\n",
    "grouped = df.groupby('Dayofweek').sum()\n",
    "display(grouped.plot(kind = 'barh'))\n",
    "grouped = grouped.reset_index()\n",
    "grouped\n",
    "\n",
    "grouped['IsWeekend'] = grouped.Dayofweek.map({0:False,1:False,2:False,3:False,4:False,5:True,6:True})\n",
    "wkend = grouped.groupby('IsWeekend').mean()\n",
    "display(wkend)\n",
    "wkend[['Entries', 'Exits']].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "\n",
    "df.head()\n",
    "df.tail()\n",
    "# df.info()\n",
    "df.index\n",
    "df.dtypes\n",
    "df.columns\n",
    "df.shape\n",
    "\n",
    "df.iloc[5:80, 2:10] # integer-location based indexing\n",
    "# df.loc[:, 'Linename'] # label-location based indexing\n",
    "# or\n",
    "df['Linename']\n",
    "# boolean indexing\n",
    "display(df.loc[(df['Entries'] > 7740888) & (df['Exits'] > 1367254), ['Station', 'Entries', 'Exits']][0:10])\n",
    "\n",
    "# update values\n",
    "df.loc[df['Entries'] > 7740888, ['Station']] = 'Station4'\n",
    "\n",
    "# create new column\n",
    "# df.loc[df['Entries'] > 7740888, 'NewCol'] = 'Busy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series\n",
    "\n",
    "linenames = df['Linename']\n",
    "linenames.unique()\n",
    "linenames.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "df.mean()\n",
    "df['Entries'].mean()\n",
    "df['Entries'].quantile(.9) # get the value for 90% quantile for a specific column\n",
    "df['Entries'].count()\n",
    "df['Entries'].std()\n",
    "df['Entries'].sum()\n",
    "# pd.options.display.max_rows = 99999\n",
    "# display(df['Entries'].cumsum()) # the cumulative sum, where each cell index contains the sum of all indices lower than, and including, itself\n",
    "df['Station'].unique()\n",
    "df['Station'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .apply() / .applymap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert every value in the DataFrame to a string\n",
    "string_df = df.applymap(lambda x: str(x))\n",
    "string_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Entries'].apply(lambda x: x+1)[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "data = pd.DataFrame({'A':np.random.randn(365).cumsum(),\n",
    "                    'B':np.random.randn(365).cumsum() + 25,\n",
    "                    'C':np.random.randn(365).cumsum() - 25}, \n",
    "                     index = pd.date_range('1/1/2018', periods = 365))\n",
    "\n",
    "# ; removes the '<matplotlib.axes._subplots.AxesSubplot at 0x8985400>' after the chart\n",
    "data.plot('A', 'B', kind = 'SCATTER');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colormaps: https://matplotlib.org/examples/color/colormaps_reference.html\n",
    "ax = data.plot.scatter('A', 'C', c = 'B', s = data['B'], colormap = 'viridis');\n",
    "# setting the aspect ratio to equal allows the viewer to easily see that the range of series A is much smaller than series C\n",
    "ax.set_aspect('equal')\n",
    "ax.set_title('Manipulating Pandas plot objects in matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.box();\n",
    "data.plot.hist(alpha = 0.7); # setting alpha level to inspect distribution overlap\n",
    "data.plot.kde();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing High Dimensional Data\n",
    "#### Scatter Matrix / Parallel Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('m1s3/Data/iris.csv')\n",
    "\n",
    "# Scatter Matrix\n",
    "pd.plotting.scatter_matrix(iris);\n",
    "\n",
    "colormap = ('skyblue', 'salmon', 'lightgreen')\n",
    "plt.figure()\n",
    "# Parallel Plots\n",
    "pd.plotting.parallel_coordinates(iris, 'species', color = colormap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('m1s4/causes_of_death.tsv', sep='\\t')\n",
    "grouped = df.groupby(['State', 'Gender'])['Deaths', 'Population'].agg(['mean', 'min', 'max', 'std'])\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped.reset_index()\n",
    "cols0 = grouped.columns.get_level_values(0)\n",
    "cols1 = grouped.columns.get_level_values(1)\n",
    "grouped.columns = [col0 + '_' + col1 if col1 != '' else col0 for col0, col1 in list(zip(cols0, cols1))]\n",
    "pivot = grouped.pivot(index='State', columns='Gender', values='Deaths_mean')\n",
    "display(pivot.head())\n",
    "pivot.plot(kind='barh', figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "## Dealing with Missing Data\n",
    "Strategies:\n",
    "- Remove Data (Rows / Columns): **.dropna()**\n",
    "- Replace\n",
    "  - Continuous Data: Best to replace with the median: **.fillna()**\n",
    "  - Categorical Data: Most common value?\n",
    "- Keep\n",
    "  - Continuous Data: **Coarse Classification (Binning)** Separate by categories (i.e. age range) and create a new category\n",
    "  - Categorical Data: Replace with a string 'NaN' / 'missing'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
